\documentclass[conference]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{kotex}
\usepackage{newtxtext,newtxmath}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}

\begin{document}

\sloppy
\setlength{\parskip}{0.3em}
\setlength{\parindent}{1em}

% Remove A, B, C from subsection numbering
\renewcommand{\thesubsection}{\arabic{subsection}}

\title{ROTA: Real-time Offensive Threat Assessment}

\author{\IEEEauthorblockN{Susie Choi}
\IEEEauthorblockA{GitHub: \url{https://github.com/susie-Choi/rota}\\
Email: sschoidev@gmail.com}}

\maketitle

% Add page numbers
\pagestyle{plain}
\thispagestyle{plain}

\begin{abstract}
오픈소스 Supply Chain의 취약점은 CVE(Common Vulnerabilities and Exposures) 발표 이전에 이미 악용되고 있으며, 단일 패키지의 취약점이 의존성 그래프를 통해 수천 개의 하위 프로젝트로 전파된다. 본 연구는 CVE 발표 전 단계에서 취약점을 탐지하는 ROTA(Real-time Offensive Threat Assessment) 시스템을 개발하고 있다. ROTA는 GitHub API 기반 Commit 데이터 수집, Neo4j 그래프 Database를 활용한 Supply Chain 영향 분석, LLM 기반 RAG(Retrieval-Augmented Generation)를 통한 이전 취약점 패턴 학습을 통합한다. 현재까지 CVE 11,441개, Commit 35,080개, 51,000개 노드로 구성된 지식 그래프를 구축했으며, 초기 분석 결과 수정 Commit을 100\% 정확도로 식별하고 보안 관련 Commit의 42.7\%를 자동 분류할 수 있었다. 향후 코드 diff 분석, 데이터셋 확장, GitHub Webhook을 통한 실시간 모니터링 구현을 통해 CVE 발표 이전 단계에서 취약점 관련 Commit을 조기 탐지할 수 있는 시스템으로 발전시킬 계획이다.
\end{abstract}

\section{서론}

\indent 현대 소프트웨어 개발은 오픈소스 생태계에 크게 의존하고 있다. 이러한 의존성 체인(Supply Chain)은 효율적인 개발을 가능하게 하지만, 동시에 심각한 보안 위험을 초래한다. 2021년 12월 발생한 Log4Shell 취약점은 Apache Log4j 라이브러리의 단일 취약점이 전 세계 수백만 개의 애플리케이션에 영향을 미친 대표적 사례다. 본 연구에서 수집한 1,666개 KEV(Known Exploited Vulnerability) 데이터 중 Log4Shell은 CVSS(Common Vulnerability Scoring System) 점수 10.0(CRITICAL)을 기록했으며, CISA(Cybersecurity and Infrastructure Security Agency)는 정부 기관에 24시간 내 패치를 의무화했다. 더욱 심각한 문제는 취약점이 CVE(Common Vulnerabilities and Exposures)로 등록되기 전 이미 공격자들이 악용하고 있다는 점이다. 본 연구에서 분석한 CVE-2012-3503(Katello secret\_token 취약점)의 경우, 수정 Commit이 CVE 발표 8일 전에 이루어졌다. 이는 취약점이 발견되고 수정되었지만, 공식적인 CVE 등록 전까지 다른 시스템들은 여전히 취약한 상태였음을 의미한다.

오픈소스 보안을 위해 사용되는 도구들은 근본적인 한계를 가진다. CVE 기반 도구의 사후 대응으로, GitHub Dependabot, Snyk 등은 이미 알려진 CVE Database를 기반으로 작동한다. 본 연구에서 수집한 11,441개 CVE 데이터를 분석한 결과, 모든 CVE는 발표 이후에만 탐지 가능했다. 즉, 취약점이 이미 공개되고 악용 가능한 상태가 된 후에야 대응이 시작된다. EPSS(Exploit Prediction Scoring System)  시간적 한계로, 본 연구에서 수집한 10,026개 EPSS 데이터를 분석한 결과, EPSS 점수가 부여되는 시점은 CVE 발표 이후였다. EPSS는 악용 가능성을 예측하지만, 역시 CVE 발표 이후에만 작동한다. 정적 분석 도구의 Supply Chain 맹점으로, 정적 분석 도구는 개별 코드의 구조적 취약점을 찾을 수 있지만, 오픈소스 의존성 체인 간의 관계로 인한 취약점 전파를 탐지하지 못한다. 또한 취약점이 도입된 시점과 맥락, 개발 과정의 행동 신호를 이해하지 못한다.

\indent 따라서 본 연구에서는 이러한 한계를 극복하기 위해 다음과 같은 가설을 기반으로 취약점 관련 commit을 조기 탐지한다.

\noindent\textbf{RQ1 (Supply Chain Propagation)}: 단일 패키지의 취약점이 의존성 그래프를 통해 하위 프로젝트로 전파될 때, 그래프 기반 분석이 영향 범위를 정확히 예측할 수 있는가

\noindent\textbf{RQ2 (Early Detection)}: GitHub API 기반 Commit 분석이 CVE 발표 전 단계에서 취약점 관련 Commit을 조기에 탐지할 수 있는가

\noindent\textbf{RQ3 (Historical Pattern Learning)}: RAG 기반 LLM 분석이 과거 유사한 CWE 유형의 취약점 패턴을 학습하여, 새로운 취약점 도입 Commit을 예측할 수 있는가

\noindent\textbf{RQ4 (Multi-signal Integration)}: Commit 메시지, 코드 diff, GitHub 행동 신호(Issue/PR), 개발자 활동 패턴을 통합한 분석이 단일 신호 분석보다 우수한가

\noindent 이에 대한 연구 가설은 다음과 같다.

\noindent\textbf{Commit 레벨 가설}:

\noindent\textbf{H1-1 (Temporal Leading Signal)}: 취약점 수정 Commit 이전 30-90일 사이에 관련 보안 Issue, PR, 개발자 논의가 증가하는 패턴이 관찰될 것이다.

\noindent\textbf{H1-2 (Code Change Pattern)}: 취약점 도입 Commit은 정상 Commit 대비 유의미하게 더 많은 코드 변경량(additions + deletions)을 가질 것이다.

\noindent\textbf{H1-3 (File Concentration)}: 취약점의 대부분이 특정 파일 유형(예: 인증, 입력 검증, 데이터베이스 접근)에 집중될 것이다.

\noindent\textbf{H1-4 (CWE Pattern Generalization)}: 동일 CWE 유형의 과거 취약점 패턴(예: CWE-79 XSS)을 학습하면, 새로운 프로젝트에서 유사한 취약점 도입을 높은 정확도로 예측할 수 있을 것이다.

\noindent\textbf{Contributor 레벨 가설}:

\noindent\textbf{H2-1 (Experience Effect)}: 프로젝트 기여 경험이 적은 신규 Contributor의 Commit이 경험이 많은 Contributor 대비 취약점을 도입할 확률이 현저히 더 높을 것이다.

\noindent\textbf{H2-2 (Developer Turnover)}: 핵심 Contributor의 이탈 후 일정 기간 내에 취약점 도입 확률이 평균 대비 증가할 것이다.

\noindent\textbf{H2-3 (Code Review Effect)}: Pull Request를 거치지 않고 직접 main branch에 푸시된 Commit이 PR 리뷰를 거친 Commit 대비 취약점 도입 확률이 현저히 더 높을 것이다.

\noindent\textbf{Supply Chain 레벨 가설}:

\noindent\textbf{H3-1 (Amplification Effect)}: 의존성 깊이가 깊을수록(depth $\geq$ 3) 취약점 영향을 받는 하위 프로젝트 수가 지수적으로 증가할 것이다.

\noindent\textbf{H3-2 (Propagation Speed)}: 상위 패키지의 취약점이 하위 프로젝트에 빠르게 전파될 것이다.

\noindent\textbf{H3-3 (Popularity Paradox)}: 의존성이 많은 인기 패키지일수록 취약점 발견 시 영향 범위는 크지만, 패치 속도는 더 빠를 것이다.

\noindent\indent 본 연구의 목적은 CVE 발표 이전 단계에서 취약점을 탐지하고, Supply Chain을 통한 영향 범위를 평가할 수 있는 시스템을 구축하는 것이다. 핵심 아이디어는 단순히 개별 코드의 취약점을 찾는 것이 아니라, 오픈소스 생태계 전체의 복합적인 신호를 분석하여 과거 취약점 패턴과의 유사도를 측정하는 것이다. 이를 위해 다음과 같은 접근을 진행하고 있다. 첫째, \textbf{다차원 데이터 수집}을 수행한다. GitHub API를 통해 Commit, Pull Request, Issue 데이터를 수집하고, Neo4j를 통해 패키지 간 의존성 관계를 모델링하며, CVE, EPSS, KEV 등 취약점 Database를 통합한다. 둘째, 오픈소스 생태계 신호 통합을 적용한다. 코드 변경 패턴, 개발자 행동 신호(Issue/PR, 경험 수준), Supply Chain 영향도(의존성 깊이, 패키지 인기도), 시계열 패턴(Commit 빈도 변화)을 다차원 특징으로 추출한다. 셋째, 패턴 기반 위험 평가를 수행한다. 과거 취약점 데이터로부터 학습한 패턴과 새로운 Commit의 유사도를 측정하여, CVE 발표 전 단계에서 위험 신호를 조기에 탐지한다. 넷째, RAG 기반 컨텍스트 제공을 활용한다. Neo4j에 저장된 과거 CVE-CWE-KEV 관계를 바탕으로, 유사한 취약점 패턴을 검색하여 LLM 분석에 컨텍스트로 제공한다.

본 연구는 기존 연구들이 CVE 발표 후 정적 코드 분석에 집중한 반면, 시간적, 공간적, 방법론적 측면에서 차별화된 접근을 제시한다. 시간적으로는 CVE 발표 이전 단계에서 취약점을 탐지하여 사전 예방을 가능하게 한다. 공간적으로는 단일 Commit이 아닌 Supply Chain 전체의 의존성 전파 경로를 추적하여 영향 범위를 분석한다. 방법론적으로는 Commit 메시지, 코드 diff, GitHub 행동 신호, 시계열 패턴을 통합한 다중 신호 분석을 수행하며, RAG 기반 이전 패턴 학습을 통해 과거 취약점 패턴을 새로운 프로젝트에 적용한다.

또한, 오픈소스 생태계의 보안 강화를 위한 실질적인 도구를 제공한다. 연구 결과물은 PyPI(Python Package Index)에 rota 라이브러리로 공개하여 실제 분석에 즉시 활용할 수 있도록 했으며, 지속적으로 업데이트하고 있다. Pull Request 머지 전 자동으로 위험도를 평가하고, 고위험 Commit을 차단할 수 있다. Supply Chain 모니터링을 통해 의존하는 패키지에서 취약점이 발생하면 즉시 알림을 받고 영향 범위를 파악할 수 있다. KEV(실제 악용 확인), EPSS(악용 가능성), 의존성 깊이를 종합하여 패치 우선순위를 자동으로 결정함으로써 제한된 보안 인력을 효율적으로 배치할 수 있다. 초기 실험에서 CVE-2012-3503의 수정 Commit을 CVE 발표 8일 전에 식별하여 조기 경보 가능성을 확인했다.


\section{선행 연구}

취약점 탐지 연구는 최근 LLM의 발전과 함께 새로운 국면을 맞이하고 있다. 초기 연구들이 정적 코드 분석과 키워드 기반 패턴 매칭에집중했다면, 최근에는 RAG 기반 LLM, 그래프 Database, Supply Chain 분석을 결합한 다차원 접근이 시도되고 있다. 그러나 대부분의 연구는 이미 공개된 CVE를 대상으로 하며, CVE 발표 전 단계에서의 조기 탐지는 여전히 미해결 과제로 남아 있다.

Du \textit{et al.} (2024)는 Vul-RAG를 제안하여 RAG 기반 LLM으로 취약점을 탐지했다 \cite{vulrag2024}. 이들은 다차원 취약점 지식을 RAG 프레임워크로 통합하여 16-24\%의 정확도 향상을 달성했으며, Linux 커널에서 10개의 미공개 버그를 탐지하고 6개의 CVE를 할당받았다. Sun \textit{et al.} (2024)은 GPT-4와 Claude를 활용한 LLM4Vuln 프레임워크를 제안했다 \cite{sun2024}. 이들은 취약점 탐지를 위한 통합 평가 프레임워크를 구축했으나, 두 연구 모두 기존 코드의 정적 분석에 초점을 맞췄으며 CVE 발표 전 조기 탐지는 다루지 않았다.

그래프 기반 접근도 활발히 연구되고 있다. Pelofske \textit{et al.} (2023)은 Neo4j 그래프 Database를 활용하여 오픈소스 인텔리전스 텍스트로부터 IP 주소, 도메인, 해시, CVE 정보를 노드로 연결하여 위협 분석을 수행했다 \cite{pelofske2023}. Ohm \textit{et al.} (2020)은 npm 생태계의 의존성 네트워크를 분석하여 취약점 전파 경로를 연구했다 \cite{ohm2020}. 그러나 이들의 연구는 정적 위협 정보 분석이나 이미 알려진 CVE의 영향 범위 분석에 한정되었다. Zhou \textit{et al.} (2017)은 Commit Message의 키워드 패턴을 분석하여 보안 패치를 식별했으나 \cite{zhou2017}, 이미 공개된 취약점의 수정 Commit을 찾는 데 집중했으며 취약점 도입 시점을 예측하지는 못했다.

NVD, EPSS, CISA KEV와 같은 취약점 Database는 보안 연구의 핵심 인프라로 자리잡았다 \cite{nvd2025, epss2025, cisa2025}. 본 연구에서는 NVD API 2.0을 통해 11,441개 CVE, 10,026개 EPSS 점수, 1,666개 KEV를 수집했다. 그러나 이 모든 시스템은 CVE 발표 이후에만 작동한다는 공통적인 한계가 있다.

기존 연구들의 한계를 종합하면, 첫째, 대부분의 연구가 CVE 발표 후 사후 분석에 집중하여 조기 경보가 불가능하다. 둘째, 정적 코드 분석에 치중하여 개발 과정의 동적 신호(GitHub 활동, 개발자 행동, 시계열 패턴)를 간과한다. 셋째, 단일 차원 분석(코드만, 또는 그래프만)으로는 복잡한 오픈소스 생태계의 취약점 패턴을 포착하기 어렵다. 넷째, Supply Chain 전파 경로와 Commit 레벨 분석을 통합한 연구가 부족하다.

본 연구는 이러한 연구 갭을 해결하기 위해 세 가지 핵심 기여를 제시한다. 첫째, CVE 발표 전 Commit 단위에서 취약점 패턴을 탐지하여 조기 경보를 가능하게 한다. ±180일 Window로 관련 Commit의 92.4\%를 포착하며, 초기 실험에서 CVE 발표 8일 전 수정 Commit 식별에 성공했다. 둘째, 코드 변경, GitHub 행동 신호, Supply Chain 영향도, 시계열 패턴을 통합한 다차원 분석을 수행한다. Neo4j에 CVE, Commit, CWE, KEV, 의존성 관계를 통합하고 RAG 기반 LLM 예측의 컨텍스트로 활용한다. 셋째, AI Agent 기반 접근으로 클러스터링 결과와 임베딩 정보를 LLM에 제공하여 생태계 맥락을 고려한 종합적 위험도 판단을 수행한다.


\section{자료 및 방법론}

본 연구는 6개 데이터 소스를 활용하여 종합적인 취약점 분석을 수행한다. 표 \ref{tab:data_sources}는 각 데이터 소스의 현황을 보여준다.

\begin{table}[h]
\centering
\caption{데이터 소스 현황}
\label{tab:data_sources}
\begin{tabular}{lrr}
\toprule
\textbf{데이터 소스} & \textbf{수집 건수} & \textbf{상태} \\
\midrule
CVE (NVD) & 11,441 & 완료 \\
EPSS & 10,026 & 완료 \\
KEV (CISA) & 1,666 & 완료 \\
GitHub Commits & 35,080 & 완료 \\
Exploits (Exploit-DB) & 30 & 완료 \\
GitHub Advisory & 3 & 완료 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{CVE 데이터}는 NVD(National Vulnerability Database) API 2.0을 통해 11,441개 CVE를 수집했다. 각 CVE는 CVE ID, 취약점 설명, CVSS 점수(0-10 범위), CWE 분류, 발표일, 최종 수정일을 포함하며, 데이터는 JSONL 형식으로 저장된다. \textbf{Commit 데이터}는 GitHub REST API v3를 통해 35,080개를 수집했으며, CVE별로 발표일 기준 ±180일 Window 내에서 수집되었다. 각 Commit은 SHA, 작성자, Commit 날짜, Commit Message, Repository 정보, 파일 변경 통계를 포함한다. 현재 3개 CVE에 대한 Commit을 수집했다: CVE-2011-3188 (Linux Kernel, 32,675개), CVE-2012-3503 (Katello, 2,011개), CVE-2012-4406 (OpenStack Swift, 394개). \textbf{KEV 데이터}는 CISA에서 제공하는 Known Exploited Vulnerability 카탈로그에서 1,666개 실제 악용이 확인된 취약점을 수집했으며, CVE ID, 취약점 이름, KEV 등록일, 패치 마감일, 랜섬웨어 사용 여부를 포함한다. \textbf{EPSS 데이터}는 FIRST에서 제공하는 Exploit Prediction Scoring System을 통해 10,026개 CVE에 대한 악용 가능성 점수를 수집했으며, 0-1 범위의 점수로 향후 30일 내 악용 확률을 예측한다. \textbf{Exploit 데이터}는 Exploit-DB에서 30개 공개 익스플로잇 코드를 수집했으며, 각 익스플로잇은 관련 CVE와 연결되어 실제 악용 가능성을 나타낸다. \textbf{GitHub Advisory 데이터}는 GitHub Security Advisory Database에서 3개 패키지 레벨 보안 권고를 수집했으며, npm, PyPI, Maven 등 패키지 매니저별 취약점 정보를 제공한다.

수집된 데이터는 Neo4j 그래프 Database에 구조화되었다. 표 \ref{tab:neo4j_nodes}는 현재 Database의 노드 현황을, 표 \ref{tab:neo4j_relationships}는 관계 현황을 보여준다. 데이터 로딩은 자동화된 스크립트를 통해 CVE 발표일 기준 ±180일 Window 필터링, CVE-Commit 관계 생성, 중복 항목 자동 제거, 시간적 데이터 누수 방지를 수행한다.


\begin{table}[h]
\centering
\caption{Neo4j Nodes 현황}
\label{tab:neo4j_nodes}
\begin{tabular}{lrl}
\toprule
\textbf{Node 유형} & \textbf{개수} & \textbf{설명} \\
\midrule
CVE & 11,441 & 취약점 정보 \\
Commit & 35,080 & GitHub Commit \\
KEV & 1,666 & 실제 악용 확인 \\
CWE & 969 & 취약점 유형 \\
CPE & 804 & 제품 식별자 \\
Product & 276 & 영향받는 제품 \\
Reference & 362 & 외부 참조 \\
Consequence & 71 & 영향 결과 \\
Vendor & 36 & 소프트웨어 벤더 \\
Package & 33 & 소프트웨어 패키지 \\
Exploit & 30 & 공개 익스플로잇 \\
Advisory & 3 & GitHub 권고 \\
GitHubSignal & 1 & 행동 신호 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Neo4j Relationships 현황}
\label{tab:neo4j_relationships}
\begin{tabular}{lrl}
\toprule
\textbf{Relationships 유형} & \textbf{개수} & \textbf{설명} \\
\midrule
HAS\_COMMIT & 35,080 & CVE → Commit \\
RELATED\_TO & 1,434 & CVE 관계 \\
HAS\_CONSEQUENCE & 1,189 & CVE → Consequence \\
AFFECTS & 891 & CVE → Product \\
HAS\_VERSION & 804 & Product → CPE \\
HAS\_REFERENCE & 379 & CVE → Reference \\
PRODUCES & 276 & Vendor → Product \\
HAS\_EXPLOIT & 141 & CVE → Exploit \\
DEPENDS\_ON & 20 & 패키지 의존성 \\
HAS\_WEAKNESS & 16 & CVE → CWE \\
HAS\_ADVISORY & 10 & Package → Advisory \\
HAS\_KEV & 9 & CVE → KEV \\
REFERENCES & 3 & Advisory → CVE \\
HAS\_SIGNAL & 1 & Package → Signal \\
\bottomrule
\end{tabular}
\end{table}

\textbf{시간 필터링}: 취약점 분석의 정확도를 높이기 위해 CVE 발표일 기준 ±180일 Window를 적용했다. 표 \ref{tab:time_window}는 시간 Window별 Commit 포착률을 보여준다.

\begin{table}[h]
\centering
\caption{시간 Window별 Commit 포착률}
\label{tab:time_window}
\begin{tabular}{lrr}
\toprule
\textbf{Window} & \textbf{Commit 수} & \textbf{포착률} \\
\midrule
$\pm$30일 & 10,523 & 27.7\% \\
$\pm$90일 & 21,320 & 56.1\% \\
$\pm$180일 & 35,080 & 92.4\% \\
$\pm$365일 & 37,928 & 99.7\% \\
\bottomrule
\end{tabular}
\end{table}

$\pm$180일 Window를 선택한 이유는 다음과 같다. 관련 Commit의 92.4\%를 포착하면서도 노이즈 감소, 저장 공간 효율화, 취약점 개발 기간 집중, Temporal data leakage 방지가 가능하기 때문이다. $\pm$365일 Window는 99.7\%를 포착하지만 추가로 얻는 2,848개 Commit(7.3\%)에 비해 저장 공간과 처리 시간이 크게 증가하므로, 효율성과 완전성의 균형을 고려하여 $\pm$180일을 선택했다.

본 연구에서는 취약점 탐지를 위해 세 가지 분석 방법을 활용하였다. 첫째, 키워드 기반 Commit 분석을 수행한다. 25개 보안 관련 키워드(보안: security, vulnerability, cve, exploit, attack, malicious; 수정: patch, fix, bug, resolve, address; 검증: sanitize, validate, escape; 권한: authentication, authorization, privilege, escalation; 위험: unsafe, insecure, leak, exposure, disclosure)를 사용하여 Commit Message를 분석했다. 각 Commit에 대해 보안 점수(키워드 출현 빈도), CVE 참조 여부(CVE-YYYY-NNNNN 패턴 존재), 수정 Commit 가능성(CVE 참조 + 보안 키워드 조합)을 계산했다. 둘째, LLM 기반 위험도 평가를 수행한다. Google Gemini 2.5 Flash를 사용하여 Commit의 취약점 도입 가능성을 평가했다. 입력으로 Commit Metadata(SHA, 작성자, 날짜, 메시지), CVE 설명 및 CWE 분류, 파일 변경 통계를 제공하고, 출력으로 위험도 점수(0-100\%), 위험 레벨(LOW, MEDIUM, HIGH, CRITICAL), 신뢰도(0-100\%), 위험 요인 목록, 추론 과정 설명을 받는다. LLM에게 CVE 정보와 Commit 정보를 제공하여 해당 Commit이 취약점을 도입했을 가능성을 0-100\% 범위로 평가하도록 요청한다. 마지막으로, 그래프 기반 RAG를 활용한다. Neo4j에 저장된 CVE, CWE, KEV, Commit 데이터를 활용하여 이전 패턴을 학습했다. RAG 시스템은 CWE 기반 유사 CVE 검색(최근 5개), 패키지 취약점 히스토리 조회(최근 10개), EPSS 트렌드 분석(유사 CVE 3개), 의존성 위험 분석(깊이 2)을 수행한다. RAG 컨텍스트는 LLM 프롬프트에 추가되어 이전 사례의 맥락을 제공하며, 이를 통해 LLM은 과거 유사한 취약점 패턴을 참고하여 더 정확한 위험도 평가를 수행할 수 있다.

\section{시스템 아키텍처}

ROTA 시스템은 바퀴(Wheel) 은유를 사용하여 설계되었다. 그림 \ref{fig:architecture}는 시스템의 전체 구조를 보여준다.

\begin{figure}[h]
\centering
\small
\begin{verbatim}
                +-------------+
                |    ORACLE   |
                +------+------+
                       |
              +--------+---------+
              |        |         |
          +---+---+ +--+--+ +----+---+
          | WHEEL |<| HUB |>|  AXLE  |
          +---+---+ +--+--+ +----+---+
              |        |         |
              +--------+---------+
                       |
                +------+-----+
                |   SPOKES   |
                +------------+
\end{verbatim}
\caption{ROTA 시스템 아키텍처}
\label{fig:architecture}
\end{figure}

\subsection{Spokes (데이터 수집 계층)}

Spokes는 다양한 소스에서 원시 데이터를 수집한다. \texttt{CVECollector}는 NVD에서 CVE 데이터를, \texttt{EPSSCollector}는 FIRST에서 EPSS 점수를, \texttt{KEVCollector}는 CISA에서 KEV 카탈로그를 수집한다. \texttt{GitHubSignalsCollector}는 GitHub에서 Commit, PR, 이슈를, \texttt{ExploitDBCollector}는 Exploit-DB에서 익스플로잇을, \texttt{GitHubAdvisoryCollector}는 GitHub Advisory를 수집한다. 모든 Collector는 재시도 로직(exponential backoff), Rate limiting 처리, JSONL 형식 출력, Metadata 추적 기능을 제공한다.

\subsection{Hub (지식 그래프 계층)}

Hub는 Neo4j 그래프 Database를 사용하여 데이터를 통합한다. 주요 구성 요소는 \texttt{DataLoader}(수집된 데이터를 Neo4j에 로드), \texttt{HubQuery}(RAG를 위한 쿼리 인터페이스), \texttt{SupplyChainAnalyzer}(의존성 그래프 분석)로 구성된다. 그래프 스키마는 CVE를 중심으로 CWE, EPSS, KEV, Commit과의 관계를 모델링하며, Package 간 의존성(DEPENDS\_ON)과 GitHub 행동 신호(HAS\_SIGNAL)를 포함한다.

\subsection{Oracle (예측 엔진)}

Oracle은 AI Agent 기반 취약점 위험 예측을 수행한다. LLM을 활용하여 다차원 신호를 종합적으로 분석하고, Wheel에서 제공하는 클러스터링 결과와 임베딩 정보를 바탕으로 생태계 맥락을 고려한 위험도를 판단한다. 세 가지 분석 모듈로 구성된다:

\subsubsection{Commit Analyzer}

개별 Commit의 취약점 위험을 분석한다. 입력 신호로 Commit Metadata(작성자, 메시지, 타임스탬프), 파일 변경(추가, 삭제, 수정), 코드 diff 분석, 위험 코드 패턴 탐지, 보안 검사 제거 탐지를 사용한다. 탐지 패턴은 \texttt{eval()}, \texttt{exec()}, \texttt{pickle.loads()}, SQL injection 패턴, 약한 암호화(MD5, SHA1), Shell 명령 실행, 제거된 보안 검증을 포함한다. 출력은 \texttt{CommitRiskResult}로 Risk Score(0.0-1.0), Risk Level(LOW, MEDIUM, HIGH, CRITICAL), Confidence(0.0-1.0), Risk factors 및 recommendations를 제공한다.

\subsubsection{Project Oracle}

프로젝트 전체의 취약점 위험을 분석한다. 입력 신호로 GitHub 활동(7-30일), Commit 빈도 및 패턴, 보안 관련 이슈/PR, 코드 리뷰 프로세스(PR 유무, 리뷰어 수), 개발자 이탈 및 경험 수준, 이전 CVE 패턴(RAG 사용)을 사용한다. RAG 컨텍스트는 CWE 기반 유사 CVE, 패키지 취약점 히스토리, EPSS 트렌드, 의존성 위험, 패키지 인기도, 유지보수자 히스토리를 포함한다. 출력은 \texttt{PredictionResult}로 Risk Score(0.0-1.0), Risk Level(LOW, MEDIUM, HIGH, CRITICAL), Confidence(0.0-1.0), Reasoning 및 recommendations를 제공한다.

\subsubsection{Integrated Oracle}

모든 분석 모듈을 통합하여 종합 평가를 수행한다. 통합 공식은 다음과 같다:

\begin{equation}
\begin{split}
R_{overall} = & \, 0.4 \cdot R_{commit} + 0.4 \cdot R_{project} \\
              & + 0.2 \cdot R_{supply\_chain}
\end{split}
\end{equation}

고위험 Commit이 있는 경우 추가 가중치를 적용한다:

\begin{equation}
R_{overall} = R_{overall} + 0.1 \cdot N_{high\_risk}
\end{equation}

출력은 \texttt{IntegratedRiskAssessment}로 전체 위험 점수 및 레벨, 구성 요소별 점수 분해, 고위험 Commit 목록, Supply chain 영향 분석, 통합 추론, 우선순위 권장사항, 알림 우선순위 레벨을 제공한다.

\subsection{Wheel (패턴 분석 계층)}

Wheel은 과거 취약점 데이터로부터 패턴을 학습하고, 새로운 Commit이 기존 취약점 패턴과 유사한지 평가한다. 코드 변경, 개발자 행동, Supply Chain 영향도 등 다차원 특징을 임베딩으로 변환하여 클러스터링을 수행하고, 새로운 Commit의 임베딩과 기존 취약점 클러스터 간의 유사도를 계산한다. 이러한 클러스터링 결과와 임베딩 정보는 LLM에 제공되어, AI Agent가 생태계 맥락을 고려한 종합적인 위험도 판단을 수행한다 (향후 구현 예정).

\subsection{Axle (평가 계층)}

Axle은 예측 시스템의 성능을 평가한다. 시간 순서를 고려한 검증 방식을 사용하는데, 예를 들면 2020년 이전 데이터로 학습한 모델이 2020년 이후 발생한 CVE를 얼마나 정확히 예측할 수 있는지 측정한다. 예측 정확도, CVE 발표 전 탐지 가능 시간(Lead Time), False Positive Rate 등의 지표를 측정하며, 기존 방법론(CVSS, EPSS 등)과 비교하여 시스템의 실효성을 검증한다 (향후 구현 예정).


\section{현재 진행 상황 및 초기 결과}

데이터셋은 현재까지 3개 CVE에 대해 35,080개 Commit을 수집하여 초기 분석을 수행했다. 표 \ref{tab:dataset}는 현재 데이터셋 현황을 보여준다.

\begin{table}[h]
\centering
\caption{분석 데이터셋 현황}
\label{tab:dataset}
\begin{tabular}{lrr}
\toprule
\textbf{CVE ID} & \textbf{Commit 수} & \textbf{프로젝트} \\
\midrule
CVE-2011-3188 & 32,675 & Linux Kernel \\
CVE-2012-3503 & 2,011 & Katello \\
CVE-2012-4406 & 394 & OpenStack Swift \\
\midrule
\textbf{합계} & \textbf{35,080} & \\
\bottomrule
\end{tabular}
\end{table}

키워드 기반 분석을 수행한 결과, 전체 35,080개 Commit 중 14,991개(42.7\%)가 보안 관련으로 분류되었다. 표 \ref{tab:commit_analysis}는 CVE별 초기 분석 결과를 보여준다.

\begin{table}[!htbp]
\centering
\caption{CVE별 Commit 분석 결과}
\label{tab:commit_analysis}
\begin{tabular}{lrrr}
\toprule
\textbf{CVE ID} & \textbf{전체} & \textbf{보안 관련} & \textbf{비율} \\
\midrule
CVE-2011-3188 & 32,675 & 14,358 & 43.9\% \\
CVE-2012-3503 & 2,011 & 454 & 22.6\% \\
CVE-2012-4406 & 394 & 179 & 45.4\% \\
\midrule
\textbf{합계} & \textbf{35,080} & \textbf{14,991} & \textbf{42.7\%} \\
\bottomrule
\end{tabular}
\end{table}

CVE-2012-3503에 대해 수정 Commit을 성공적으로 식별했다. 해당 Commit은 2012-08-17(CVE 발표 8일 전)에 Lukas Zapletal에 의해 작성되었으며, Commit Message에 "850745 - secret\_token is not generated properly (CVE-2012-3503)"라는 명시적 CVE 참조를 포함하고 있었다. 이 초기 결과는 키워드 기반 분석이 명시적 CVE 참조를 포함한 수정 Commit 식별에 효과적일 수 있음을 시사한다.

Linux Kernel의 IPv4/IPv6 MD4 시퀀스 번호 생성 취약점(CVE-2011-3188)을 분석한 결과, 매우 큰 코드베이스(32,675개 Commit)에서 다수의 보안 관련 변경(14,358개, 43.9\%)이 발견되었다. 여러 CVE 참조(CVE-2012-1179, CVE-2009-4307 등)가 포함되어 있었으며, CVE 발표일 당일(2012-05-24)에도 Commit이 존재했다. 상위 보안 Commit으로는 \texttt{1a5a9906}(mm: thp: fix pmd\_bad(), CVE-2012-1179 참조), \texttt{371fd835}(Bluetooth: Fix deadlocks, security/validate 키워드), \texttt{d50f2ab6}(ext4: fix undefined behavior, CVE-2009-4307 참조)가 식별되었다. 그러나 Commit 수가 너무 많아 코드 diff 분석 없이는 특정 취약점 도입 Commit을 식별하기 어려웠다.

Katello 설치 스크립트의 부적절한 secret\_token 생성 취약점(CVE-2012-3503)을 분석한 결과, 수정 Commit(\texttt{1781f22b})을 성공적으로 식별했으며 CVE 발표 8일 전에 수정되었음을 확인했다. 그러나 취약점은 초기 설치 스크립트에서 도입되어 $\pm$180일 Window 밖에 위치했다. 수정 Commit 이전 10개 Commit을 Gemini 2.5 Flash로 분석한 결과, 모든 Commit이 LOW 위험도(0-1\% 가능성)로 평가되었으며, 이는 취약점을 도입한 Commit이 $\pm$180일 Window 밖에 있을 가능성을 시사한다. 이는 수정 Commit은 식별 가능하지만 취약점 도입 Commit은 훨씬 이전일 수 있으며, 전체 히스토리 분석의 필요성을 보여준다.

OpenStack Swift의 memcached Metadata Repository에서 안전하지 않은 pickle 사용 취약점(CVE-2012-4406)을 분석한 결과, 높은 보안 관련 Commit 비율(179개, 45.4\%)을 보였으며, 디렉토리 순회 검증 Commit(\texttt{cc1907ee}, 2012-06-19)이 발견되었다. CVE 날짜 전후로 다수의 보안 개선이 이루어졌으며, 활발한 보안 개발 기간이었음을 확인했다. 상위 보안 Commit으로는 \texttt{357b12dc}(Remove IP-based container-sync ACLs, security/attack/malicious 키워드), \texttt{cc1907ee}(Validate devices to avoid directory traversals), \texttt{edd38035}(Handle exception correctly)가 식별되었다. CVE는 2012-10-22에 발표되었으며, Commit 범위는 2012-04-26부터 2012-11-21까지로 취약점 개발 기간 동안 활발한 개발이 진행되었다.

표 \ref{tab:time_window_effect}는 각 CVE에 대한 시간 Window 필터링 효과를 보여준다.

\begin{table}[h]
\centering
\caption{CVE별 시간 Window 필터링 효과}
\label{tab:time_window_effect}
\begin{tabular}{lrrr}
\toprule
\textbf{CVE ID} & \textbf{±180일} & \textbf{전체} & \textbf{필터율} \\
\midrule
CVE-2011-3188 & 32,675 & 35,628 & 8.3\% \\
CVE-2012-3503 & 2,011 & 2,011 & 0\% \\
CVE-2012-4406 & 394 & 396 & 0.5\% \\
\midrule
\textbf{합계} & \textbf{35,080} & \textbf{38,035} & \textbf{7.8\%} \\
\bottomrule
\end{tabular}
\end{table}

±180일 Window는 전체 Commit의 92.2\%를 포착하면서도 7.8\%의 노이즈를 제거했다.


\section{결론 및 향후 연구}

초기 분석 결과, 키워드 기반 분석으로 CVE-2012-3503의 수정 Commit을 100\% 정확도로 식별했으나, 취약점 도입 Commit은 $\pm$180일 Window 밖에 있어 탐지하지 못했다. 이는 수정 Commit이 명시적 CVE 참조와 보안 키워드를 포함하는 반면, 도입 Commit은 일반적인 기능 추가로 보이기 때문이다. $\pm$180일 Window는 관련 Commit의 92.4\%를 포착하면서도 저장 공간을 효율화하지만, 초기 코드나 장기 잠복 취약점 탐지에는 한계가 있다. 25개 보안 키워드로 전체 Commit의 42.7\%를 보안 관련으로 분류했으며, 프로젝트 특성에 따라 22.6\%~45.4\% 범위를 보였다.

현재 한계점은 다음과 같다. 첫째, Commit Message만으로는 취약점 도입 여부를 판단하기 어려워 코드 diff 분석이 필요하다. 둘째, 3개 CVE로는 일반화하기 어려워 100개 이상으로 확장이 필요하다. 셋째, 취약점 도입 Commit에 대한 Ground Truth 레이블이 부족하다. 넷째, $\pm$180일 Window로는 초기 코드나 점진적 취약점을 놓칠 수 있다.

\subsection{향후 연구 방향}

본 연구는 앞서 제시한 가설들을 체계적으로 검증하기 위해 네 가지 방향으로 진행할 계획이다. 첫째, 데이터셋을 현재 3개 CVE에서 100개 이상으로 확장하여 통계적으로 유의미한 분석을 수행한다. KEV 카탈로그 1,666개 중 높은 EPSS 점수를 가진 CVE를 우선 선정하고 Python, Java, JavaScript 생태계를 균형있게 포함하여 각 CVE당 평균 1,000개 Commit을 수집함으로써 총 100,000개 이상의 데이터를 확보한다. 이를 통해 수정 Commit 이전 30-90일 사이 보안 이슈/PR 증가율 측정, 취약점 도입 Commit의 평균 코드 변경량 계산, 취약점 발생 파일 유형 분포 분석을 수행하여 H1-1, H1-2, H1-3 가설을 검증한다. 둘째, GitHub API를 통해 각 Contributor의 프로젝트 기여 이력, 경험 수준, PR 리뷰 프로세스 데이터를 수집하여 신규 Contributor와 경험 많은 Contributor의 취약점 도입 확률을 비교하고, 핵심 Contributor 이탈 전후 3개월간 취약점 발생률 변화를 추적하며, 적절한 통계적 방법을 통해 H2-1, H2-2, H2-3 가설을 검증한다. 셋째, Neo4j 그래프 Database에 패키지 간 의존성 관계를 완전히 구축하고 의존성 깊이별 영향받는 하위 프로젝트 수를 측정하며, 상위 패키지 취약점 발생 시점부터 하위 프로젝트 패치 완료까지 평균 시간을 추적하여 인기 패키지와 일반 패키지의 패치 속도를 비교함으로써 H3-1, H3-2, H3-3 가설을 검증한다. 넷째, 동일 CWE 유형의 과거 취약점 패턴을 RAG 기반으로 학습하고 새로운 프로젝트에서 유사한 취약점 도입을 예측하며, Temporal Validation을 통해 2020년 이전 데이터로 학습하고 2020년 이후 CVE를 예측하여 예측 성능 지표 및 조기 탐지 시간을 측정함으로써 H1-4 가설을 검증한다.

본 연구가 완성되면 다음과 같은 기여를 할 것으로 기대된다. 학술적으로는 Commit 레벨에서 zero-day 취약점을 예측하는 새로운 연구 방향을 제시하고, $\pm$180일 Window의 효과를 검증하며, 코드/텍스트/그래프/시계열 신호를 통합한 다중 데이터 분석과 RAG 기반 예측 방법론을 제안한다. CVE 발표 전 단계에서 취약점을 탐지하고, Supply Chain 보안을 강화하며, CI/CD 파이프라인에 통합 가능한 우선순위 결정 도구를 제공한다. 사회적으로는 오픈소스 생태계의 보안을 강화하고, zero-day 공격으로 인한 피해를 감소시키며, 보안 대응 시간을 단축하고, 제한된 보안 인력을 효율적으로 활용할 수 있도록 기여한다.

\subsection{결론}

본 연구는 CVE 발표 전 취약점 탐지를 위한 ROTA 시스템을 개발하고 있다. 35,080개 Commit 분석을 통해 수정 Commit 식별 가능성을 확인했으나, 취약점 도입 시점 탐지에는 코드 diff 분석과 전체 히스토리 추적이 필요함을 확인했다. Neo4j 기반 지식 그래프(51,000개 노드)를 구축하여 RAG 기반 예측의 기반을 마련했으며, 향후 데이터셋 확장 및 가설 검증을 통해 실제 적용 가능한 시스템으로 발전시킬 계획이다.


\begin{thebibliography}{00}

\bibitem{vulrag2024} X. Du et al., ``Vul-RAG: Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG,'' arXiv preprint arXiv:2406.11147, 2024. [Online]. Available: \url{https://arxiv.org/abs/2406.11147}

\bibitem{sun2024} Y. Sun, D. Wu, et al., ``LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning,'' arXiv preprint arXiv:2401.16185, 2024. [Online]. Available: \url{https://arxiv.org/abs/2401.16185}

\bibitem{pelofske2023} E. Pelofske et al., ``Cybersecurity Threat Hunting and Vulnerability Analysis Using a Neo4j Graph Database,'' arXiv preprint arXiv:2301.12013, 2023. [Online]. Available: \url{https://arxiv.org/abs/2301.12013}

\bibitem{ohm2020} M. Ohm, H. Plate, A. Sykosch, and M. Meier, ``Backstabber's Knife Collection: A Review of Open Source Software Supply Chain Attacks,'' in Proc. Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA), 2020, pp. 23-43. [Online]. Available: \url{https://arxiv.org/abs/2005.09535}

\bibitem{zhou2017} Y. Zhou and A. Sharma, ``Automated Identification of Security Issues from Commit Messages and Bug Reports,'' in Proc. 11th Joint Meeting on Foundations of Software Engineering (ESEC/FSE), 2017, pp. 914-925. [Online]. Available: \url{https://asankhaya.github.io/pdf/automated-identification-of-security-}\allowbreak\url{issues-from-commit-messages-and-bug-reports.pdf}

\bibitem{nvd2025} National Institute of Standards and Technology, ``National Vulnerability Database,'' 2025. [Online]. Available: \url{https://nvd.nist.gov/}

\bibitem{epss2025} FIRST, ``Exploit Prediction Scoring System (EPSS),'' 2025. [Online]. Available: \url{https://www.first.org/epss/}

\bibitem{cisa2025} Cybersecurity and Infrastructure Security Agency, ``Known Exploited Vulnerabilities Catalog,'' 2025. [Online]. Available: \url{https://www.cisa.gov/known-exploited-vulnerabilities-catalog}

\bibitem{log4shell} ``CVE-2021-44228: Apache Log4j2 Remote Code Execution Vulnerability,'' National Vulnerability Database, 2021. [Online]. Available: \url{https://nvd.nist.gov/vuln/detail/CVE-2021-44228}

\bibitem{github_api} GitHub, ``GitHub REST API Documentation,'' 2025. [Online]. Available: \url{https://docs.github.com/en/rest}

\bibitem{neo4j} Neo4j, Inc., ``Neo4j Graph Database,'' 2025. [Online]. Available: \url{https://neo4j.com/}

\bibitem{gemini} Google, ``Gemini API Documentation,'' 2025. [Online]. Available: \url{https://ai.google.dev/}

\end{thebibliography}

\end{document}
