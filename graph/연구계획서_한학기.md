# Zero-Day Defense 연구 프로젝트 계획서 (한 학기 버전)

## 1. 연구 주제

### 1.1 연구 제목
**그래프 분석과 LLM을 활용한 오픈소스 패키지 취약점 위험도 예측 시스템 프로토타입**

### 1.2 연구 배경
현재 소프트웨어 보안은 CVE(Common Vulnerabilities and Exposures) 공개 후 패치를 적용하는 사후 대응 방식에 의존하고 있습니다. Log4Shell(CVE-2021-44228) 같은 대규모 보안 사고는 CVE 공개부터 패치 적용까지의 시간적 공백 동안 막대한 피해를 발생시킵니다.

본 연구는 CVE 정보가 없는 상태에서 관찰 가능한 사전 신호(그래프 구조, 과거 이력, 코드 패턴)를 분석하여 잠재적으로 위험한 패키지를 예측하는 시스템의 프로토타입을 개발합니다.

### 1.3 한 학기 연구 목표
1. **소규모 데이터셋 구축**: Python 생태계(PyPI)의 주요 패키지 1,000-5,000개 대상
2. **기본 신호 추출**: 그래프 중심성, 과거 취약점 이력, 기본 코드 메트릭
3. **간단한 위험도 예측 모델**: 신호 기반 점수 계산 + LLM 보조 분석
4. **1개 사례 검증**: Log4Shell을 Historical Validation으로 검증
5. **프로토타입 시스템**: 기본적인 API 및 시각화 인터페이스

### 1.4 연구 범위 제한 (한 학기 내 달성 가능)
- **데이터 규모**: 전체 생태계가 아닌 주요 패키지 1,000-5,000개로 제한
- **신호 종류**: 핵심 신호 3-4가지로 제한 (그래프, 과거 이력, 기본 코드 메트릭)
- **검증 사례**: Log4Shell 1건으로 제한 (Equifax 등은 향후 연구로)
- **LLM 활용**: 전체 패키지가 아닌 상위 위험 후보 100개만 분석
- **시각화**: 3D 대신 2D 시각화로 단순화

---

## 2. 연구에 활용할 데이터

### 2.1 데이터 수집 범위 (현실적 규모)

#### 2.1.1 패키지 선정 기준
**대상**: PyPI 생태계의 주요 패키지 1,000-5,000개

**선정 기준**:
- 다운로드 수 상위 1,000개 (인기 패키지)
- 과거 CVE 이력이 있는 패키지 500개
- 핵심 인프라 패키지 (requests, numpy, django 등) 500개
- 무작위 샘플 1,000-3,000개

**예상 데이터 규모**: 약 5-10GB (전체 생태계 대비 1/10 규모)

#### 2.1.2 패키지 메타데이터
**출처**: PyPI API (https://pypi.org/pypi/{package}/json)

**수집 항목**:
- 패키지 이름, 버전, 설명
- 의존성 관계 (requires_dist)
- 다운로드 통계 (pypistats API)
- 릴리스 날짜, 유지보수 상태

**수집 방법**: Python requests 라이브러리로 API 호출
**예상 소요 시간**: 1-2일 (API rate limit 고려)

#### 2.1.3 과거 취약점 이력
**출처**: 
- NVD (National Vulnerability Database) API
- GitHub Advisory Database

**수집 항목**:
- CVE ID 및 공개 날짜
- CVSS 점수 (Critical/High만 집중)
- 취약점 유형 (RCE, XSS 등)

**시간 범위**: 2015-2024년 (10년간)
**중요 제약**: Log4Shell 검증 시 2021년 11월 1일 이전 데이터만 사용

#### 2.1.4 코드 레벨 데이터 (간소화)
**출처**: GitHub 공개 저장소

**수집 항목** (기본 메트릭만):
- 코드 복잡도 (radon 라이브러리 사용)
- 위험 함수 키워드 검색 (eval, exec, system 등)
- 파일 수, 코드 라인 수

**제한사항**: 
- 전체 소스코드 다운로드 대신 GitHub API로 통계만 수집
- 상위 위험 후보 100개만 상세 분석

#### 2.1.5 의존성 그래프
**구축 방법**: NetworkX 라이브러리로 방향 그래프 생성
- 노드: 패키지 (1,000-5,000개)
- 엣지: 의존성 관계 (A depends on B)

**저장 형식**: 
- NetworkX pickle 파일 (로컬 분석용)
- JSON 파일 (시각화용)

---

## 3. 분석 방향 및 단계별 계획

### 3.1 전체 연구 흐름 (3단계로 단순화)

```
[Phase 1] 데이터 수집 및 그래프 구축 (3주)
    ↓
[Phase 2] 신호 추출 및 위험도 점수 계산 (4주)
    ↓
[Phase 3] Log4Shell 검증 및 시각화 (3주)
```

---

### 3.2 Phase 1: 데이터 수집 및 그래프 구축 (3주)

#### Week 1-2: 패키지 데이터 수집
**목표**: PyPI에서 1,000-5,000개 패키지 메타데이터 수집

**작업 내용**:
1. PyPI API로 인기 패키지 목록 수집
2. 각 패키지의 메타데이터 다운로드
3. 의존성 관계 파싱
4. JSON 파일로 저장

**산출물**:
- `packages.json`: 패키지 메타데이터
- `dependencies.json`: 의존성 관계

**사용 도구**: Python requests, pandas

#### Week 3: 취약점 이력 수집 및 그래프 구축
**목표**: NVD에서 CVE 데이터 수집, 의존성 그래프 생성

**작업 내용**:
1. NVD API로 2015-2024년 CVE 데이터 수집
2. CVE와 패키지 매칭
3. NetworkX로 의존성 그래프 생성
4. 그래프 기본 통계 확인 (노드 수, 엣지 수, 연결 성분)

**산출물**:
- `vulnerabilities.json`: CVE 이력
- `dependency_graph.gpickle`: 의존성 그래프
- `graph_stats.txt`: 그래프 기본 통계

**사용 도구**: NetworkX, requests

---

### 3.3 Phase 2: 신호 추출 및 위험도 점수 계산 (4주)

#### Week 4: 그래프 신호 추출
**목표**: 그래프 중심성 지표 계산

**작업 내용**:
1. PageRank 계산 (전역 중요도)
2. In-degree 계산 (얼마나 많은 패키지가 의존하는지)
3. Downstream Impact 계산 (하류 영향 범위)

**산출물**:
- `graph_signals.json`: 각 패키지의 그래프 신호

**핵심 지표**:
```json
{
  "package_name": {
    "pagerank": 0.0023,
    "in_degree": 152,
    "downstream_impact": 4523
  }
}
```

**사용 도구**: NetworkX

#### Week 5: 과거 취약점 패턴 신호 추출
**목표**: 각 패키지의 과거 취약점 이력 분석

**작업 내용**:
1. 패키지별 CVE 빈도 계산
2. Critical/High CVE 비율 계산
3. 평균 CVSS 점수 계산
4. 최근 취약점 발생 추세 분석

**산출물**:
- `vulnerability_patterns.json`: 취약점 패턴 신호

**핵심 지표**:
```json
{
  "package_name": {
    "total_cves": 7,
    "critical_cves": 3,
    "avg_cvss": 8.2,
    "last_cve_days_ago": 180
  }
}
```

#### Week 6: 코드 레벨 신호 추출 (간소화)
**목표**: 상위 위험 후보 100개의 코드 메트릭 수집

**작업 내용**:
1. GitHub API로 저장소 통계 수집
2. 위험 키워드 검색 (eval, exec, system 등)
3. 코드 복잡도 계산 (가능한 경우)

**산출물**:
- `code_signals.json`: 코드 레벨 신호 (100개만)

**제한사항**: 전체 패키지가 아닌 상위 후보만 분석

#### Week 7: 위험도 점수 계산 및 LLM 분석
**목표**: 신호를 통합하여 위험도 점수 계산, 상위 100개 LLM 분석

**작업 내용**:
1. 신호 정규화 (0-1 범위)
2. 가중 평균으로 기본 위험도 점수 계산
   ```
   Risk_Score = 0.4 × Graph_Signal + 0.5 × Vulnerability_Pattern + 0.1 × Code_Signal
   ```
3. 상위 100개 패키지에 대해 LLM 분석
   - 프롬프트: 각 패키지의 신호를 제공하고 위험도 평가 요청
   - GPT-4 또는 Claude 사용
4. 최종 위험도 점수 계산

**산출물**:
- `risk_scores.json`: 모든 패키지의 위험도 점수
- `llm_analysis.json`: 상위 100개의 LLM 분석 결과

---

### 3.4 Phase 3: Log4Shell 검증 및 시각화 (3주)

#### Week 8-9: Log4Shell Historical Validation
**목표**: 2021년 11월 1일 시점에 Log4j를 고위험으로 식별할 수 있었는지 검증

**작업 내용**:
1. **시간 분할 설정**
   - Cutoff: 2021년 11월 1일
   - CVE 공개: 2021년 12월 9일

2. **과거 데이터 재구성**
   - 2021년 11월 1일 이전 데이터만 사용
   - 이후 CVE 정보 모두 제거

3. **예측 실행**
   - Phase 2의 전체 파이프라인 실행
   - Log4j의 위험도 순위 확인

4. **결과 분석**
   - Log4j가 상위 몇 %에 포함되었는지
   - 어떤 신호가 위험을 나타냈는지
   - Lead Time 계산 (약 38일)

**성공 기준**:
- Log4j가 상위 5% 이내에 포함되면 성공
- 상위 1% 이내면 매우 성공적

**산출물**:
- `log4shell_validation.json`: 검증 결과
- `log4shell_analysis.md`: 상세 분석 보고서

#### Week 10: 시각화 및 프로토타입 완성
**목표**: 결과를 시각화하고 간단한 웹 인터페이스 구축

**작업 내용**:
1. **2D 위험 지도 생성**
   - X축: PageRank (중요도)
   - Y축: 과거 취약점 빈도
   - 점 크기: 위험도 점수
   - 색상: Critical CVE 여부

2. **간단한 웹 인터페이스** (Streamlit 사용)
   - 패키지 검색 기능
   - 위험도 점수 표시
   - 신호 상세 정보 표시
   - 2D 위험 지도 인터랙티브 표시

3. **보고서 작성**
   - 연구 방법론 정리
   - Log4Shell 검증 결과
   - 한계점 및 향후 연구 방향

**산출물**:
- `risk_map_2d.html`: 2D 위험 지도
- Streamlit 앱: 프로토타입 인터페이스
- `final_report.pdf`: 최종 보고서

---

## 4. 평가 방법 (간소화)

### 4.1 Log4Shell 검증 지표
- **순위 평가**: Log4j가 전체 중 상위 몇 %에 포함되었는지
- **Lead Time**: CVE 공개 대비 얼마나 일찍 탐지했는지 (목표: 30일 이상)
- **신호 분석**: 어떤 신호가 위험을 나타냈는지 정성적 분석

### 4.2 시스템 평가
- **처리 속도**: 1,000-5,000개 패키지 분석 소요 시간
- **사용성**: 웹 인터페이스의 직관성
- **확장 가능성**: 더 많은 패키지로 확장 가능한지

---

## 5. 기대 성과 (한 학기 범위)

### 5.1 학술적 성과
- **프로토타입 시스템**: 잠재 위협 탐지의 가능성 입증
- **방법론 검증**: 사전 신호 기반 예측의 유효성 확인
- **향후 연구 기반**: 전체 규모 연구를 위한 기초 마련

### 5.2 실용적 성과
- **위험 패키지 식별**: 1,000-5,000개 중 고위험 패키지 목록
- **시각화 도구**: 패키지 위험도를 직관적으로 확인할 수 있는 인터페이스
- **오픈소스 공개**: 코드 및 데이터를 GitHub에 공개

### 5.3 학습 성과
- 그래프 분석 기법 습득
- LLM API 활용 경험
- 보안 데이터 분석 역량
- 실세계 문제 해결 경험

---

## 6. 한 학기 일정표

| 주차 | 단계 | 주요 작업 | 산출물 |
|------|------|-----------|--------|
| 1-2 | Phase 1 | 패키지 메타데이터 수집 | packages.json, dependencies.json |
| 3 | Phase 1 | CVE 수집 및 그래프 구축 | vulnerabilities.json, dependency_graph.gpickle |
| 4 | Phase 2 | 그래프 신호 추출 | graph_signals.json |
| 5 | Phase 2 | 취약점 패턴 신호 추출 | vulnerability_patterns.json |
| 6 | Phase 2 | 코드 신호 추출 (100개) | code_signals.json |
| 7 | Phase 2 | 위험도 점수 계산 + LLM | risk_scores.json, llm_analysis.json |
| 8-9 | Phase 3 | Log4Shell 검증 | log4shell_validation.json |
| 10 | Phase 3 | 시각화 및 보고서 | risk_map_2d.html, final_report.pdf |

---

## 7. 필요 리소스

### 7.1 개발 환경
- Python 3.9+
- 주요 라이브러리: NetworkX, pandas, requests, openai/anthropic
- 개발 도구: VS Code, Jupyter Notebook

### 7.2 API 및 서비스
- PyPI API (무료)
- NVD API (무료, rate limit 있음)
- GitHub API (무료, rate limit 있음)
- OpenAI API 또는 Claude API (유료, 예상 비용: $50-100)

### 7.3 컴퓨팅 리소스
- 로컬 PC (8GB RAM 이상 권장)
- 저장 공간: 20GB 이상

---

## 8. 위험 요소 및 대응 방안

### 8.1 데이터 수집 지연
**위험**: API rate limit으로 데이터 수집 지연
**대응**: 
- 캐싱 활용
- 필요시 패키지 수를 1,000개로 축소
- 미리 수집된 데이터셋 활용 (Libraries.io 등)

### 8.2 LLM API 비용
**위험**: LLM API 비용 초과
**대응**:
- 분석 대상을 상위 50개로 축소
- GPT-3.5 같은 저렴한 모델 사용
- 배치 처리로 비용 절감

### 8.3 Log4Shell 검증 실패
**위험**: Log4j를 고위험으로 식별하지 못함
**대응**:
- 신호 가중치 조정
- 추가 신호 탐색
- 실패 원인 분석도 중요한 연구 결과

---

## 9. 향후 확장 방향 (한 학기 이후)

### 9.1 단기 확장 (방학 중)
- 패키지 수 확대: 10,000-50,000개
- 추가 검증 사례: Equifax, 기타 Critical CVE
- 코드 분석 강화: 전체 패키지 대상

### 9.2 중기 확장 (다음 학기)
- 다른 생태계 추가: Maven (Java), npm (JavaScript)
- 3D 시각화 구현
- 실시간 모니터링 시스템

### 9.3 장기 목표 (1년 후)
- 전체 규모 시스템 구축
- 학술 논문 작성 및 투고
- 실용 서비스 런칭
